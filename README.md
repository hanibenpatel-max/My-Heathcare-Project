# My-Heathcare-Project

**Name:** Haniben Patel
**Student ID:** 501345072
**Supervisor Name:** Tamer Abdou

## Project Overview 

This project focuses on analyzing a healthcare dataset to uncover patterns, trends, and insights that can inform better decision-making. The Analysis involves:

- **1.Data Analysis Section:**
  Summerrizing key dataset features using descriptive statistics and visualization, hightlighting    patterns, trends, and outliers.
  
- **2.Data preparation Section:**
  Cleaning, preprocessing, transformationg, and preparing data for modeling.

- **3.Model Evaluation Section:**
  Implementing machine learning models, evaluating their performance using metrics such as precision, recall, and F2-score, and discussing findings.

--- 

## Repository Contents:

- 'data/' -> Contains the healthcare dataset files.
- 'notebooks/' -> Google Colab notebooks with code for analysis, preprocessing, and modeling.
- 'sscripts/' -> python scripts for reproducible data analysis and visualization.
- 'images/' -> sample plots and visualizations from analysis.
- 'README.md/' -> project summary, methodology, and repository documantation.

---

## Key Tools and Libraries:

- python : pandas, numpy, matplotlib, seaborn, scikit-learn
- Google colab for developmeny and exceution

--- 

## Sample Visualizations:

some Examples of the analysis performed in this project:

### 1. Distribution of Patients by Age
![Age Distribution]

### 2. Correlation Heatmap of Feature
![Correlation Heatmap]

### 3. Boxplot Admission Type by Billing Amount
![AdmissionType by Billing Amount]

## Step-by-step Methodology

This project follows a structured approach to analyze the healthcare dataset and evaluate models. 

### 1. Data Exploration and Analysis

- Loads the healthcare datset and inspects its structure.
- Computes descriptive statistics such as mean, median, standard deviation, and distribution of    key features.
- Visualizes data using histograms, boxplots, and correlation heatmaos toidentify patterns,        trends, and outliers.

### 2. Data Cleaning and Preparation

- Handles missing values, duplicates, and incosistent entries.
- Encodes categorical variables and scales numerical features.
- Splits data into training and testing sets for modeling.

### 3. Model Development and Evaluation

- Implements multiple machine learning models including Logistic Regression, Random Forest, and    XGBoost.
- Evaluates models using metrics such as precision, recall, F1-score, and accuracy.
- Compares models performance and selects the best model for prediction.

### 4. Visualization and Reporting

- Generates plots and charts to summarize analysis and model performance.
- Provides insights and recommendations based on analysis results.
  
### 5. Scripts for Reproducibility

- Contains standalone python scripts that replicate data cleaning, analysis, and modeling steps.
- Ensures reproducibility without opening notbooks.

### Observations

- XGBoost outperformed other models with the highest F1-score, indicating strong overall
  perforance.
- Random Forest also performed well, showing stability across different metrics.
- Logistic Regression Provides a simple baseline with resonable performance.

  


